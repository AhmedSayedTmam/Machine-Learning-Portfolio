{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Training and Prediction with Sagemaker Scikit-learn\n",
    "This tutorial shows you how to use [Scikit-learn](https://scikit-learn.org/stable/) with Sagemaker by utilizing the pre-built container. Scikit-learn is a popular Python machine learning framework. It includes a number of different algorithms for classification, regression, clustering, dimensionality reduction, and data/feature pre-processing. \n",
    "\n",
    "The [sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk) module  makes it easy to take existing scikit-learn code, which we will show by training a model on the IRIS dataset and generating a set of predictions. For more information about the Scikit-learn container, see the [sagemaker-scikit-learn-containers](https://github.com/aws/sagemaker-scikit-learn-container) repository and the [sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk) repository.\n",
    "\n",
    "For more on Scikit-learn, please visit the Scikit-learn website: <http://scikit-learn.org/stable/>.\n",
    "\n",
    "### Table of contents\n",
    "* [Upload the data for training](#upload_data)\n",
    "* [Create a Scikit-learn script to train with](#create_sklearn_script)\n",
    "* [Create the SageMaker Scikit Estimator](#create_sklearn_estimator)\n",
    "* [Train the SKLearn Estimator on the Iris data](#train_sklearn)\n",
    "* [Using the trained model to make inference requests](#inferece)\n",
    " * [Deploy the model](#deploy)\n",
    " * [Choose some data and use it for a prediction](#prediction_request)\n",
    " * [Endpoint cleanup](#endpoint_cleanup)\n",
    "* [Batch Transform](#batch_transform)\n",
    " * [Prepare Input Data](#prepare_input_data)\n",
    " * [Run Transform Job](#run_transform_job)\n",
    " * [Check Output Data](#check_output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: this example requires SageMaker Python SDK v2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U sagemaker>=2.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets create our Sagemaker session and role, and create a S3 prefix to use for the notebook example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "prefix = \"Scikit-iris\"\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the data for training <a class=\"anchor\" id=\"upload_data\"></a>\n",
    "\n",
    "When training large models with huge amounts of data, you'll typically use big data tools, like Amazon Athena, AWS Glue, or Amazon EMR, to create your data in S3. For the purposes of this example, we're using a sample of the classic [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set), which is included with Scikit-learn. We will load the dataset, write locally, then write the dataset to s3 to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn import datasets\n",
    "\n",
    "# Load Iris dataset, then join labels and features\n",
    "iris = datasets.load_iris()\n",
    "joined_iris = np.insert(iris.data, 0, iris.target, axis=1)\n",
    "\n",
    "# Create directory and write csv\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "np.savetxt(\"./data/iris.csv\", joined_iris, delimiter=\",\", fmt=\"%1.1f, %1.3f, %1.3f, %1.3f, %1.3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the data locally, we can use use the tools provided by the SageMaker Python SDK to upload the data to a default bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = \"data\"\n",
    "\n",
    "train_input = sagemaker_session.upload_data(\n",
    "    WORK_DIRECTORY, key_prefix=\"{}/{}\".format(prefix, WORK_DIRECTORY)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.100</th>\n",
       "      <th>3.500</th>\n",
       "      <th>1.400</th>\n",
       "      <th>0.200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.0   5.100   3.500   1.400   0.200\n",
       "0    0.0     4.9     3.0     1.4     0.2\n",
       "1    0.0     4.7     3.2     1.3     0.2\n",
       "2    0.0     4.6     3.1     1.5     0.2\n",
       "3    0.0     5.0     3.6     1.4     0.2\n",
       "4    0.0     5.4     3.9     1.7     0.4\n",
       "..   ...     ...     ...     ...     ...\n",
       "144  2.0     6.7     3.0     5.2     2.3\n",
       "145  2.0     6.3     2.5     5.0     1.9\n",
       "146  2.0     6.5     3.0     5.2     2.0\n",
       "147  2.0     6.2     3.4     5.4     2.3\n",
       "148  2.0     5.9     3.0     5.1     1.8\n",
       "\n",
       "[149 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Scikit-learn script to train with <a class=\"anchor\" id=\"create_sklearn_script\"></a>\n",
    "SageMaker can now run a scikit-learn script using the `SKLearn` estimator. When executed on SageMaker a number of helpful environment variables are available to access properties of the training environment, such as:\n",
    "\n",
    "* `SM_MODEL_DIR`: A string representing the path to the directory to write model artifacts to. Any artifacts saved in this folder are uploaded to S3 for model hosting after the training job completes.\n",
    "* `SM_OUTPUT_DIR`: A string representing the filesystem path to write output artifacts to. Output artifacts may include checkpoints, graphs, and other files to save, not including model artifacts. These artifacts are compressed and uploaded to S3 to the same S3 prefix as the model artifacts.\n",
    "\n",
    "Supposing two input channels, 'train' and 'test', were used in the call to the `SKLearn` estimator's `fit()` method, the following environment variables will be set, following the format `SM_CHANNEL_[channel_name]`:\n",
    "\n",
    "* `SM_CHANNEL_TRAIN`: A string representing the path to the directory containing data in the 'train' channel\n",
    "* `SM_CHANNEL_TEST`: Same as above, but for the 'test' channel.\n",
    "\n",
    "A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to model_dir so that it can be hosted later. Hyperparameters are passed to your script as arguments and can be retrieved with an `argparse.ArgumentParser` instance. For example, the script that we will run in this notebook is the below:\n",
    "\n",
    "```python\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hyperparameters are described here. In this simple example we are just including one hyperparameter.\n",
    "    parser.add_argument('--max_leaf_nodes', type=int, default=-1)\n",
    "\n",
    "    # Sagemaker specific arguments. Defaults are set in the environment variables.\n",
    "    parser.add_argument('--output-data-dir', type=str, default=os.environ['SM_OUTPUT_DATA_DIR'])\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "    parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Take the set of files and read them all into a single pandas dataframe\n",
    "    input_files = [ os.path.join(args.train, file) for file in os.listdir(args.train) ]\n",
    "    if len(input_files) == 0:\n",
    "        raise ValueError(('There are no files in {}.\\n' +\n",
    "                          'This usually indicates that the channel ({}) was incorrectly specified,\\n' +\n",
    "                          'the data specification in S3 was incorrectly specified or the role specified\\n' +\n",
    "                          'does not have permission to access the data.').format(args.train, \"train\"))\n",
    "    raw_data = [ pd.read_csv(file, header=None, engine=\"python\") for file in input_files ]\n",
    "    train_data = pd.concat(raw_data)\n",
    "\n",
    "    # labels are in the first column\n",
    "    train_y = train_data.iloc[:, 0]\n",
    "    train_X = train_data.iloc[:, 1:]\n",
    "\n",
    "    # Here we support a single hyperparameter, 'max_leaf_nodes'. Note that you can add as many\n",
    "    # as your training my require in the ArgumentParser above.\n",
    "    max_leaf_nodes = args.max_leaf_nodes\n",
    "\n",
    "    # Now use scikit-learn's decision tree classifier to train the model.\n",
    "    clf = tree.DecisionTreeClassifier(max_leaf_nodes=max_leaf_nodes)\n",
    "    clf = clf.fit(train_X, train_y)\n",
    "\n",
    "    # Print the coefficients of the trained classifier, and save the coefficients\n",
    "    joblib.dump(clf, os.path.join(args.model_dir, \"model.joblib\"))\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialized and return fitted model\n",
    "    \n",
    "    Note that this should have the same name as the serialized model in the main method\n",
    "    \"\"\"\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the Scikit-learn container imports your training script, you should always put your training code in a main guard `(if __name__=='__main__':)` so that the container does not inadvertently run your training code at the wrong point in execution.\n",
    "\n",
    "For more information about training environment variables, please visit https://github.com/aws/sagemaker-containers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SageMaker Scikit Estimator <a class=\"anchor\" id=\"create_sklearn_estimator\"></a>\n",
    "\n",
    "To run our Scikit-learn training script on SageMaker, we construct a `sagemaker.sklearn.estimator.sklearn` estimator, which accepts several constructor arguments:\n",
    "\n",
    "* __entry_point__: The path to the Python script SageMaker runs for training and prediction.\n",
    "* __role__: Role ARN\n",
    "* __instance_type__ *(optional)*: The type of SageMaker instances for training. __Note__: Because Scikit-learn does not natively support GPU training, Sagemaker Scikit-learn does not currently support training on GPU instance types.\n",
    "* __sagemaker_session__ *(optional)*: The session used to train on Sagemaker.\n",
    "* __hyperparameters__ *(optional)*: A dictionary passed to the train function as hyperparameters.\n",
    "\n",
    "To see the code for the SKLearn Estimator, see here: https://github.com/aws/sagemaker-python-sdk/tree/master/src/sagemaker/sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "script_path = \"scikit_learn_iris.py\"\n",
    "\n",
    "sklearn = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "#     instance_type=\"ml.c4.xlarge\",\n",
    "    instance_type=\"local\",\n",
    "    role=role,\n",
    "#     sagemaker_session=sagemaker_session,  # we use local mode\n",
    "    hyperparameters={\"max_leaf_nodes\": 30},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SKLearn Estimator on Iris data <a class=\"anchor\" id=\"train_sklearn\"></a>\n",
    "Training is very simple, just call `fit` on the Estimator! This will start a SageMaker Training job that will download the data for us, invoke our scikit-learn code (in the provided script file), and save any model artifacts that the script creates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 1h214rqkf7-algo-1-jlyis ... \n",
      "Creating 1h214rqkf7-algo-1-jlyis ... done\n",
      "Attaching to 1h214rqkf7-algo-1-jlyis\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m 2021-07-29 12:09:20,001 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m 2021-07-29 12:09:20,005 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m 2021-07-29 12:09:20,016 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m 2021-07-29 12:09:20,219 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m 2021-07-29 12:09:20,234 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m 2021-07-29 12:09:20,249 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m 2021-07-29 12:09:20,260 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m \n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m Training Env:\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m \n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m {\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     },\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"current_host\": \"algo-1-jlyis\",\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m         \"algo-1-jlyis\"\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     ],\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m         \"max_leaf_nodes\": 30\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     },\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m         \"train\": {\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m         }\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     },\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2021-07-29-12-07-50-632\",\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"master_hostname\": \"algo-1-jlyis\",\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-168402291854/sagemaker-scikit-learn-2021-07-29-12-07-50-632/source/sourcedir.tar.gz\",\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"module_name\": \"scikit_learn_iris\",\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m         \"current_host\": \"algo-1-jlyis\",\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m             \"algo-1-jlyis\"\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m         ]\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     },\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m     \"user_entry_point\": \"scikit_learn_iris.py\"\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m }\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m \n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m Environment variables:\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m \n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_HOSTS=[\"algo-1-jlyis\"]\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_HPS={\"max_leaf_nodes\":30}\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_USER_ENTRY_POINT=scikit_learn_iris.py\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-jlyis\",\"hosts\":[\"algo-1-jlyis\"]}\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_CURRENT_HOST=algo-1-jlyis\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_MODULE_NAME=scikit_learn_iris\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-168402291854/sagemaker-scikit-learn-2021-07-29-12-07-50-632/source/sourcedir.tar.gz\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-jlyis\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-jlyis\"],\"hyperparameters\":{\"max_leaf_nodes\":30},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2021-07-29-12-07-50-632\",\"log_level\":20,\"master_hostname\":\"algo-1-jlyis\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-168402291854/sagemaker-scikit-learn-2021-07-29-12-07-50-632/source/sourcedir.tar.gz\",\"module_name\":\"scikit_learn_iris\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-jlyis\",\"hosts\":[\"algo-1-jlyis\"]},\"user_entry_point\":\"scikit_learn_iris.py\"}\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_USER_ARGS=[\"--max_leaf_nodes\",\"30\"]\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m SM_HP_MAX_LEAF_NODES=30\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m \n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m \n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m /miniconda3/bin/python scikit_learn_iris.py --max_leaf_nodes 30\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m \n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m \n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis |\u001b[0m 2021-07-29 12:09:21,179 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36m1h214rqkf7-algo-1-jlyis exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "sklearn.fit({\"train\": train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the trained model to make inference requests <a class=\"anchor\" id=\"inference\"></a>\n",
    "\n",
    "### Deploy the model <a class=\"anchor\" id=\"deploy\"></a>\n",
    "\n",
    "Deploying the model to SageMaker hosting just requires a `deploy` call on the fitted model. This call takes an instance count and instance type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to pyxqzqrxyn-algo-1-9ez9z\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m 2021-07-29 12:12:08,214 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m 2021-07-29 12:12:08,217 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m 2021-07-29 12:12:08,218 INFO - sagemaker-containers - nginx config: \n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m worker_processes auto;\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m daemon off;\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m pid /tmp/nginx.pid;\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m error_log  /dev/stderr;\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m \n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m worker_rlimit_nofile 4096;\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m \n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m events {\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m   worker_connections 2048;\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m }\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m \n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m http {\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m   include /etc/nginx/mime.types;\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m   default_type application/octet-stream;\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m   access_log /dev/stdout combined;\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m \n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m   upstream gunicorn {\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m     server unix:/tmp/gunicorn.sock;\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m   }\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m \n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m   server {\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m     listen 8080 deferred;\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m     client_max_body_size 0;\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m \n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m     keepalive_timeout 3;\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m \n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m     location ~ ^/(ping|invocations|execution-parameters) {\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m       proxy_set_header Host $http_host;\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m       proxy_redirect off;\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m       proxy_read_timeout 60s;\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m       proxy_pass http://gunicorn;\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m     }\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m \n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m     location / {\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m       return 404 \"{}\";\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m     }\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m \n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m   }\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m }\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m \n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m \n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m 2021-07-29 12:12:08,410 INFO - sagemaker-containers - Module scikit_learn_iris does not provide a setup.py. \n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m Generating setup.py\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m 2021-07-29 12:12:08,410 INFO - sagemaker-containers - Generating setup.cfg\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m 2021-07-29 12:12:08,411 INFO - sagemaker-containers - Generating MANIFEST.in\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m 2021-07-29 12:12:08,411 INFO - sagemaker-containers - Installing module with the following command:\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m /miniconda3/bin/python -m pip install . \n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m Building wheels for collected packages: scikit-learn-iris\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m   Building wheel for scikit-learn-iris (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m \u001b[?25h  Created wheel for scikit-learn-iris: filename=scikit_learn_iris-1.0.0-py2.py3-none-any.whl size=5708 sha256=369e27a74f74c3a3c7d2abd1f582cb8675e2c6dfefeee4e498464c2725126fd9\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-dss_yj2n/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m Successfully built scikit-learn-iris\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m Installing collected packages: scikit-learn-iris\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m Successfully installed scikit-learn-iris-1.0.0\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m 2021/07/29 12:12:10 [crit] 13#13: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m 172.18.0.1 - - [29/Jul/2021:12:12:10 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"python-urllib3/1.26.5\"\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m [2021-07-29 12:12:10 +0000] [30] [INFO] Starting gunicorn 20.0.4\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m [2021-07-29 12:12:10 +0000] [30] [INFO] Listening at: unix:/tmp/gunicorn.sock (30)\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m [2021-07-29 12:12:10 +0000] [30] [INFO] Using worker: gevent\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m [2021-07-29 12:12:10 +0000] [33] [INFO] Booting worker with pid: 33\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m [2021-07-29 12:12:10 +0000] [34] [INFO] Booting worker with pid: 34\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m 2021-07-29 12:12:15,541 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "!\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m 172.18.0.1 - - [29/Jul/2021:12:12:16 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"python-urllib3/1.26.5\"\n"
     ]
    }
   ],
   "source": [
    "# predictor = sklearn.deploy(initial_instance_count=1, instance_type=\"ml.m5.xlarge\")\n",
    "predictor = sklearn.deploy(initial_instance_count=1, instance_type=\"local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose some data and use it for a prediction <a class=\"anchor\" id=\"prediction_request\"></a>\n",
    "\n",
    "In order to do some predictions, we'll extract some of the data we used for training and do predictions against it. This is, of course, bad statistical practice, but a good way to see how the mechanism works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       1    2    3    4\n",
       " 40   5.0  3.5  1.3  0.3\n",
       " 41   4.5  2.3  1.3  0.3\n",
       " 42   4.4  3.2  1.3  0.2\n",
       " 43   5.0  3.5  1.6  0.6\n",
       " 44   5.1  3.8  1.9  0.4\n",
       " 45   4.8  3.0  1.4  0.3\n",
       " 46   5.1  3.8  1.6  0.2\n",
       " 47   4.6  3.2  1.4  0.2\n",
       " 48   5.3  3.7  1.5  0.2\n",
       " 49   5.0  3.3  1.4  0.2\n",
       " 90   5.5  2.6  4.4  1.2\n",
       " 91   6.1  3.0  4.6  1.4\n",
       " 92   5.8  2.6  4.0  1.2\n",
       " 93   5.0  2.3  3.3  1.0\n",
       " 94   5.6  2.7  4.2  1.3\n",
       " 95   5.7  3.0  4.2  1.2\n",
       " 96   5.7  2.9  4.2  1.3\n",
       " 97   6.2  2.9  4.3  1.3\n",
       " 98   5.1  2.5  3.0  1.1\n",
       " 99   5.7  2.8  4.1  1.3\n",
       " 140  6.7  3.1  5.6  2.4\n",
       " 141  6.9  3.1  5.1  2.3\n",
       " 142  5.8  2.7  5.1  1.9\n",
       " 143  6.8  3.2  5.9  2.3\n",
       " 144  6.7  3.3  5.7  2.5\n",
       " 145  6.7  3.0  5.2  2.3\n",
       " 146  6.3  2.5  5.0  1.9\n",
       " 147  6.5  3.0  5.2  2.0\n",
       " 148  6.2  3.4  5.4  2.3,\n",
       " 40     0.0\n",
       " 41     0.0\n",
       " 42     0.0\n",
       " 43     0.0\n",
       " 44     0.0\n",
       " 45     0.0\n",
       " 46     0.0\n",
       " 47     0.0\n",
       " 48     0.0\n",
       " 49     0.0\n",
       " 90     1.0\n",
       " 91     1.0\n",
       " 92     1.0\n",
       " 93     1.0\n",
       " 94     1.0\n",
       " 95     1.0\n",
       " 96     1.0\n",
       " 97     1.0\n",
       " 98     1.0\n",
       " 99     1.0\n",
       " 140    2.0\n",
       " 141    2.0\n",
       " 142    2.0\n",
       " 143    2.0\n",
       " 144    2.0\n",
       " 145    2.0\n",
       " 146    2.0\n",
       " 147    2.0\n",
       " 148    2.0\n",
       " Name: 0, dtype: float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "shape = pd.read_csv(\"data/iris.csv\", header=None)\n",
    "\n",
    "a = [50 * i for i in range(3)]\n",
    "b = [40 + i for i in range(10)]\n",
    "indices = [i + j for i, j in itertools.product(a, b)]\n",
    "\n",
    "test_data = shape.iloc[indices[:-1]]\n",
    "test_X = test_data.iloc[:, 1:]\n",
    "test_y = test_data.iloc[:, 0]\n",
    "test_X, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction is as easy as calling predict with the predictor we got back from deploy and the data we want to do predictions with. The output from the endpoint return an numerical representation of the classification prediction; in the original dataset, these are flower names, but in this example the labels are numerical. We can compare against the original label that we parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m 2021-07-29 12:13:06,905 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2.]\n",
      "\u001b[36mpyxqzqrxyn-algo-1-9ez9z |\u001b[0m 172.18.0.1 - - [29/Jul/2021:12:13:07 +0000] \"POST /invocations HTTP/1.1\" 200 360 \"-\" \"python-urllib3/1.26.5\"\n"
     ]
    }
   ],
   "source": [
    "print(predictor.predict(test_X.values))\n",
    "print(test_y.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoint cleanup <a class=\"anchor\" id=\"endpoint_cleanup\"></a>\n",
    "\n",
    "When you're done with the endpoint, you'll want to clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gracefully stopping... (press Ctrl+C again to force)\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Transform <a class=\"anchor\" id=\"batch_transform\"></a>\n",
    "We can also use the trained model for asynchronous batch inference on S3 data using SageMaker Batch Transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a SKLearn Transformer from the trained SKLearn Estimator\n",
    "# transformer = sklearn.transformer(instance_count=1, instance_type=\"ml.m5.xlarge\")\n",
    "transformer = sklearn.transformer(instance_count=1, instance_type=\"local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Input Data <a class=\"anchor\" id=\"prepare_input_data\"></a>\n",
    "We will extract 10 random samples of 100 rows from the training data, then split the features (X) from the labels (Y). Then upload the input data to a given location in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Randomly sample the iris dataset 10 times, then split X and Y\n",
    "mkdir -p batch_data/XY batch_data/X batch_data/Y\n",
    "for i in {0..9}; do\n",
    "    cat data/iris.csv | shuf -n 100 > batch_data/XY/iris_sample_${i}.csv\n",
    "    cat batch_data/XY/iris_sample_${i}.csv | cut -d',' -f2- > batch_data/X/iris_sample_X_${i}.csv\n",
    "    cat batch_data/XY/iris_sample_${i}.csv | cut -d',' -f1 > batch_data/Y/iris_sample_Y_${i}.csv\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload input data from local filesystem to S3\n",
    "batch_input_s3 = sagemaker_session.upload_data(\"batch_data/X\", key_prefix=prefix + \"/batch_input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Transform Job <a class=\"anchor\" id=\"run_transform_job\"></a>\n",
    "Using the Transformer, run a transform job on the S3 input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to 3tw9f2rct7-algo-1-6ql22\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 2021-07-29 12:15:32,350 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 2021-07-29 12:15:32,353 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 2021-07-29 12:15:32,354 INFO - sagemaker-containers - nginx config: \n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m worker_processes auto;\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m daemon off;\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m pid /tmp/nginx.pid;\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m error_log  /dev/stderr;\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m \n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m worker_rlimit_nofile 4096;\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m \n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m events {\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m   worker_connections 2048;\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m }\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m \n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m http {\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m   include /etc/nginx/mime.types;\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m   default_type application/octet-stream;\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m   access_log /dev/stdout combined;\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m \n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m   upstream gunicorn {\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m     server unix:/tmp/gunicorn.sock;\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m   }\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m \n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m   server {\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m     listen 8080 deferred;\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m     client_max_body_size 0;\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m \n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m     keepalive_timeout 3;\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m \n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m     location ~ ^/(ping|invocations|execution-parameters) {\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m       proxy_set_header Host $http_host;\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m       proxy_redirect off;\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m       proxy_read_timeout 60s;\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m       proxy_pass http://gunicorn;\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m     }\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m \n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m     location / {\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m       return 404 \"{}\";\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m     }\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m \n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m   }\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m }\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m \n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m \n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 2021-07-29 12:15:32,526 INFO - sagemaker-containers - Module scikit_learn_iris does not provide a setup.py. \n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m Generating setup.py\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 2021-07-29 12:15:32,526 INFO - sagemaker-containers - Generating setup.cfg\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 2021-07-29 12:15:32,526 INFO - sagemaker-containers - Generating MANIFEST.in\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 2021-07-29 12:15:32,526 INFO - sagemaker-containers - Installing module with the following command:\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m /miniconda3/bin/python -m pip install . \n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m Building wheels for collected packages: scikit-learn-iris\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m   Building wheel for scikit-learn-iris (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m \u001b[?25h  Created wheel for scikit-learn-iris: filename=scikit_learn_iris-1.0.0-py2.py3-none-any.whl size=5708 sha256=387257af7d5bb924d72c0266388ae98315110c25bf7daae8017255ecb9609537\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-nial65zp/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m Successfully built scikit-learn-iris\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m Installing collected packages: scikit-learn-iris\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m Successfully installed scikit-learn-iris-1.0.0\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m [2021-07-29 12:15:34 +0000] [30] [INFO] Starting gunicorn 20.0.4\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m [2021-07-29 12:15:34 +0000] [30] [INFO] Listening at: unix:/tmp/gunicorn.sock (30)\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m [2021-07-29 12:15:34 +0000] [30] [INFO] Using worker: gevent\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m [2021-07-29 12:15:34 +0000] [33] [INFO] Booting worker with pid: 33\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m [2021-07-29 12:15:34 +0000] [34] [INFO] Booting worker with pid: 34\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 2021-07-29 12:15:35,444 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 172.18.0.1 - - [29/Jul/2021:12:15:36 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"python-urllib3/1.26.5\"\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 172.18.0.1 - - [29/Jul/2021:12:15:36 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"python-urllib3/1.26.5\"\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 2021-07-29 12:15:36,640 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 172.18.0.1 - - [29/Jul/2021:12:15:37 +0000] \"POST /invocations HTTP/1.1\" 200 500 \"-\" \"python-urllib3/1.26.5\"\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 172.18.0.1 - - [29/Jul/2021:12:15:37 +0000] \"POST /invocations HTTP/1.1\" 200 500 \"-\" \"python-urllib3/1.26.5\"\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 172.18.0.1 - - [29/Jul/2021:12:15:37 +0000] \"POST /invocations HTTP/1.1\" 200 500 \"-\" \"python-urllib3/1.26.5\"\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 172.18.0.1 - - [29/Jul/2021:12:15:37 +0000] \"POST /invocations HTTP/1.1\" 200 500 \"-\" \"python-urllib3/1.26.5\"\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 172.18.0.1 - - [29/Jul/2021:12:15:37 +0000] \"POST /invocations HTTP/1.1\" 200 500 \"-\" \"python-urllib3/1.26.5\"\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 172.18.0.1 - - [29/Jul/2021:12:15:37 +0000] \"POST /invocations HTTP/1.1\" 200 500 \"-\" \"python-urllib3/1.26.5\"\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 172.18.0.1 - - [29/Jul/2021:12:15:37 +0000] \"POST /invocations HTTP/1.1\" 200 500 \"-\" \"python-urllib3/1.26.5\"\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 172.18.0.1 - - [29/Jul/2021:12:15:37 +0000] \"POST /invocations HTTP/1.1\" 200 500 \"-\" \"python-urllib3/1.26.5\"\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 172.18.0.1 - - [29/Jul/2021:12:15:37 +0000] \"POST /invocations HTTP/1.1\" 200 500 \"-\" \"python-urllib3/1.26.5\"\n",
      "\u001b[36m3tw9f2rct7-algo-1-6ql22 |\u001b[0m 172.18.0.1 - - [29/Jul/2021:12:15:37 +0000] \"POST /invocations HTTP/1.1\" 200 500 \"-\" \"python-urllib3/1.26.5\"\n",
      "Gracefully stopping... (press Ctrl+C again to force)\n",
      ".Waiting for transform job: sagemaker-scikit-learn-2021-07-29-12-15-29-800\n",
      "."
     ]
    }
   ],
   "source": [
    "# Start a transform job and wait for it to finish\n",
    "transformer.transform(batch_input_s3, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + transformer.latest_transform_job.job_name)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Output Data  <a class=\"anchor\" id=\"check_output_data\"></a>\n",
    "After the transform job has completed, download the output data from S3. For each file \"f\" in the input data, we have a corresponding file \"f.out\" containing the predicted labels from each input row. We can compare the predicted labels to the true labels saved earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-168402291854/sagemaker-scikit-learn-2021-07-29-12-15-29-800/sagemaker-scikit-learn-2021-07-29-12-15-29-800/iris_sample_X_1.csv.out to batch_data/output/sagemaker-scikit-learn-2021-07-29-12-15-29-800/iris_sample_X_1.csv.out\n",
      "download: s3://sagemaker-us-east-1-168402291854/sagemaker-scikit-learn-2021-07-29-12-15-29-800/sagemaker-scikit-learn-2021-07-29-12-15-29-800/iris_sample_X_9.csv.out to batch_data/output/sagemaker-scikit-learn-2021-07-29-12-15-29-800/iris_sample_X_9.csv.out\n",
      "download: s3://sagemaker-us-east-1-168402291854/sagemaker-scikit-learn-2021-07-29-12-15-29-800/sagemaker-scikit-learn-2021-07-29-12-15-29-800/iris_sample_X_0.csv.out to batch_data/output/sagemaker-scikit-learn-2021-07-29-12-15-29-800/iris_sample_X_0.csv.out\n",
      "download: s3://sagemaker-us-east-1-168402291854/sagemaker-scikit-learn-2021-07-29-12-15-29-800/sagemaker-scikit-learn-2021-07-29-12-15-29-800/iris_sample_X_4.csv.out to batch_data/output/sagemaker-scikit-learn-2021-07-29-12-15-29-800/iris_sample_X_4.csv.out\n",
      "download: s3://sagemaker-us-east-1-168402291854/sagemaker-scikit-learn-2021-07-29-12-15-29-800/sagemaker-scikit-learn-2021-07-29-12-15-29-800/iris_sample_X_6.csv.out to batch_data/output/sagemaker-scikit-learn-2021-07-29-12-15-29-800/iris_sample_X_6.csv.out\n",
      "download: s3://sagemaker-us-east-1-168402291854/sagemaker-scikit-learn-2021-07-29-12-15-29-800/sagemaker-scikit-learn-2021-07-29-12-15-29-800/iris_sample_X_2.csv.out to batch_data/output/sagemaker-scikit-learn-2021-07-29-12-15-29-800/iris_sample_X_2.csv.out\n",
      "download: s3://sagemaker-us-east-1-168402291854/sagemaker-scikit-learn-2021-07-29-12-15-29-800/sagemaker-scikit-learn-2021-07-29-12-15-29-800/iris_sample_X_5.csv.out to batch_data/output/sagemaker-scikit-learn-2021-07-29-12-15-29-800/iris_sample_X_5.csv.out\n",
      "download: s3://sagemaker-us-east-1-168402291854/sagemaker-scikit-learn-2021-07-29-12-15-29-800/sagemaker-scikit-learn-2021-07-29-12-15-29-800/iris_sample_X_8.csv.out to batch_data/output/sagemaker-scikit-learn-2021-07-29-12-15-29-800/iris_sample_X_8.csv.out\n",
      "download: s3://sagemaker-us-east-1-168402291854/sagemaker-scikit-learn-2021-07-29-12-15-29-800/sagemaker-scikit-learn-2021-07-29-12-15-29-800/iris_sample_X_7.csv.out to batch_data/output/sagemaker-scikit-learn-2021-07-29-12-15-29-800/iris_sample_X_7.csv.out\n",
      "download: s3://sagemaker-us-east-1-168402291854/sagemaker-scikit-learn-2021-07-29-12-15-29-800/sagemaker-scikit-learn-2021-07-29-12-15-29-800/iris_sample_X_3.csv.out to batch_data/output/sagemaker-scikit-learn-2021-07-29-12-15-29-800/iris_sample_X_3.csv.out\n",
      "head: error reading â€˜batch_data/output/sagemaker-scikit-learn-2021-07-29-12-15-29-800â€™: Is a directory\n"
     ]
    }
   ],
   "source": [
    "# Download the output data from S3 to local filesystem\n",
    "batch_output = transformer.output_path\n",
    "!mkdir -p batch_data/output\n",
    "!aws s3 cp --recursive $batch_output/ batch_data/output/\n",
    "# Head to see what the batch output looks like\n",
    "!head batch_data/output/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,100d0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "1,100d0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "1,100d0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "1,100d0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "1,100d0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "1,100d0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "1,100d0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "1,100d0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "1,100d0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 0.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 2.0\n",
      "< 2.0\n",
      "< 0.0\n",
      "< 1.0\n",
      "< 1.0\n",
      "< 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cat: batch_data/output/iris_sample_X_1.csv.out: No such file or directory\n",
      "cat: batch_data/output/iris_sample_X_2.csv.out: No such file or directory\n",
      "cat: batch_data/output/iris_sample_X_3.csv.out: No such file or directory\n",
      "cat: batch_data/output/iris_sample_X_4.csv.out: No such file or directory\n",
      "cat: batch_data/output/iris_sample_X_5.csv.out: No such file or directory\n",
      "cat: batch_data/output/iris_sample_X_6.csv.out: No such file or directory\n",
      "cat: batch_data/output/iris_sample_X_7.csv.out: No such file or directory\n",
      "cat: batch_data/output/iris_sample_X_8.csv.out: No such file or directory\n",
      "cat: batch_data/output/iris_sample_X_9.csv.out: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# For each sample file, compare the predicted labels from batch output to the true labels\n",
    "for i in {1..9}; do\n",
    "    diff -s batch_data/Y/iris_sample_Y_${i}.csv \\\n",
    "        <(cat batch_data/output/iris_sample_X_${i}.csv.out | sed 's/[[\"]//g' | sed 's/, \\|]/\\n/g') \\\n",
    "        | sed \"s/\\/dev\\/fd\\/63/batch_data\\/output\\/iris_sample_X_${i}.csv.out/\"\n",
    "done"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
