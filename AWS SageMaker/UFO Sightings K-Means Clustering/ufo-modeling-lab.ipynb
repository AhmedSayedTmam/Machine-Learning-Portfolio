{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UFO Sightings K-Means Clustering\n",
    "### Modeling Lab\n",
    "\n",
    "The goal of this notebook is to analyze where Mr. K should build his extraterrestrial life facilities using the K-Means algorithm. \n",
    "\n",
    "What we plan on accomplishing is the following:\n",
    "1. [Load dataset onto Notebook instance from S3](#Step-1:-Loading-the-data-from-Amazon-S3)\n",
    "2. [Cleaning, transforming, and preparing the data](#Step-2:-Cleaning,-transforming,-and-preparing-the-data)\n",
    "3. [Create and train our model](#Step-3:-Create-and-train-our-model)\n",
    "4. [Viewing the results](#Step-4:-Viewing-the-results)\n",
    "5. [Visualize using QuickSight](https://docs.aws.amazon.com/quicksight/latest/user/create-a-data-set-s3.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's go ahead and import all the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker.amazon.common as smac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading the data from Amazon S3\n",
    "Next, lets get the UFO sightings data that is stored in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "bucket = 'ml-tamam'\n",
    "prefix = 'k-means-dataset'\n",
    "data_key = 'ufo_fullset.csv'\n",
    "data_location = 's3://{}/{}/{}'.format(bucket, prefix, data_key)\n",
    "\n",
    "df = pd.read_csv(data_location, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reportedTimestamp</th>\n",
       "      <th>eventDate</th>\n",
       "      <th>eventTime</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>weather</th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>sighting</th>\n",
       "      <th>physicalEvidence</th>\n",
       "      <th>contact</th>\n",
       "      <th>researchOutcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1977-04-04T04:02:23.340Z</td>\n",
       "      <td>1977-03-31</td>\n",
       "      <td>23:46</td>\n",
       "      <td>circle</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>rain</td>\n",
       "      <td>Ila</td>\n",
       "      <td>Bashirian</td>\n",
       "      <td>47.329444</td>\n",
       "      <td>-122.578889</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>explained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1982-11-22T02:06:32.019Z</td>\n",
       "      <td>1982-11-15</td>\n",
       "      <td>22:04</td>\n",
       "      <td>disk</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>partly cloudy</td>\n",
       "      <td>Eriberto</td>\n",
       "      <td>Runolfsson</td>\n",
       "      <td>52.664913</td>\n",
       "      <td>-1.034894</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>explained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992-12-07T19:06:52.482Z</td>\n",
       "      <td>1992-12-07</td>\n",
       "      <td>19:01</td>\n",
       "      <td>circle</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>clear</td>\n",
       "      <td>Miller</td>\n",
       "      <td>Watsica</td>\n",
       "      <td>38.951667</td>\n",
       "      <td>-92.333889</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>explained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-24T21:06:34.898Z</td>\n",
       "      <td>2011-02-21</td>\n",
       "      <td>20:56</td>\n",
       "      <td>disk</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>partly cloudy</td>\n",
       "      <td>Clifton</td>\n",
       "      <td>Bechtelar</td>\n",
       "      <td>41.496944</td>\n",
       "      <td>-71.367778</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>explained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1991-03-09T16:18:45.501Z</td>\n",
       "      <td>1991-03-09</td>\n",
       "      <td>11:42</td>\n",
       "      <td>circle</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>mostly cloudy</td>\n",
       "      <td>Jayda</td>\n",
       "      <td>Ebert</td>\n",
       "      <td>47.606389</td>\n",
       "      <td>-122.330833</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>explained</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          reportedTimestamp   eventDate eventTime   shape  duration  \\\n",
       "0  1977-04-04T04:02:23.340Z  1977-03-31     23:46  circle         4   \n",
       "1  1982-11-22T02:06:32.019Z  1982-11-15     22:04    disk         4   \n",
       "2  1992-12-07T19:06:52.482Z  1992-12-07     19:01  circle        49   \n",
       "3  2011-02-24T21:06:34.898Z  2011-02-21     20:56    disk        13   \n",
       "4  1991-03-09T16:18:45.501Z  1991-03-09     11:42  circle        17   \n",
       "\n",
       "   witnesses        weather firstName    lastName   latitude   longitude  \\\n",
       "0          1           rain       Ila   Bashirian  47.329444 -122.578889   \n",
       "1          1  partly cloudy  Eriberto  Runolfsson  52.664913   -1.034894   \n",
       "2          1          clear    Miller     Watsica  38.951667  -92.333889   \n",
       "3          1  partly cloudy   Clifton   Bechtelar  41.496944  -71.367778   \n",
       "4          1  mostly cloudy     Jayda       Ebert  47.606389 -122.330833   \n",
       "\n",
       "  sighting physicalEvidence contact researchOutcome  \n",
       "0        Y                N       N       explained  \n",
       "1        Y                Y       N       explained  \n",
       "2        Y                N       N       explained  \n",
       "3        Y                N       N       explained  \n",
       "4        Y                N       N       explained  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Cleaning, transforming, and preparing the data\n",
    "Create another DataFrame with just the latitude and longitude attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo = df[['latitude', 'longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.329444</td>\n",
       "      <td>-122.578889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.664913</td>\n",
       "      <td>-1.034894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.951667</td>\n",
       "      <td>-92.333889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.496944</td>\n",
       "      <td>-71.367778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.606389</td>\n",
       "      <td>-122.330833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude   longitude\n",
       "0  47.329444 -122.578889\n",
       "1  52.664913   -1.034894\n",
       "2  38.951667  -92.333889\n",
       "3  41.496944  -71.367778\n",
       "4  47.606389 -122.330833"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18000 entries, 0 to 17999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   latitude   18000 non-null  float64\n",
      " 1   longitude  18000 non-null  float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 281.4 KB\n"
     ]
    }
   ],
   "source": [
    "df_geo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any missing values? False\n"
     ]
    }
   ],
   "source": [
    "missing_values = df_geo.isnull().values.any()\n",
    "print('Are there any missing values? {}'.format(missing_values))\n",
    "if(missing_values):\n",
    "    df_geo[df_geo.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's go ahead and transform the pandas DataFrame (our dataset) into a numpy.ndarray. When we do this each row is converted to a Record object. According to the documentation, this is what the K-Means algorithm expects as training data. This is what we will use as training data for our model.\n",
    "\n",
    "[See the documentation for input training](https://sagemaker.readthedocs.io/en/stable/kmeans.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  47.329445, -122.57889 ],\n",
       "       [  52.664913,   -1.034894],\n",
       "       [  38.951668,  -92.333885],\n",
       "       ...,\n",
       "       [  36.86639 ,  -83.888885],\n",
       "       [  35.385834,  -94.39833 ],\n",
       "       [  29.883055,  -97.94111 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = df_geo.values.astype('float32')\n",
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create and train our model\n",
    "In this step we will import and use the built-in SageMaker K-Means algorithm. We will set the number of cluster to 10 (for our 10 sensors), specify the instance type we want to train on, and the location of where we want our model artifact to live. \n",
    "\n",
    "[See the documentation of hyperparameters here](https://docs.aws.amazon.com/sagemaker/latest/dg/k-means-api-config.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import KMeans\n",
    "\n",
    "num_clusters = 10\n",
    "output_location = 's3://' + bucket + '/model-artifacts'\n",
    "\n",
    "kmeans = KMeans(role=role,\n",
    "               instance_count=1,\n",
    "               instance_type='ml.c4.xlarge',\n",
    "               output_path=output_location,\n",
    "                use_spot_instances=True,\n",
    "                max_run=900,\n",
    "                max_wait=1200,\n",
    "                checkpoint_s3_uri='s3://{}/{}/checkpoint'.format(bucket, prefix),\n",
    "               k=num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the job name kmeans-geo-job-20210626111948\n"
     ]
    }
   ],
   "source": [
    "job_name = 'kmeans-geo-job-{}'.format(datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "print('Here is the job name {}'.format(job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-26 11:19:58 Starting - Starting the training job...\n",
      "2021-06-26 11:20:01 Starting - Launching requested ML instancesProfilerReport-1624706398: InProgress\n",
      "......\n",
      "2021-06-26 11:21:14 Starting - Preparing the instances for training............\n",
      "2021-06-26 11:23:15 Downloading - Downloading input data\n",
      "2021-06-26 11:23:15 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:39 INFO 140569316194112] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-input.json: {'init_method': 'random', 'mini_batch_size': '5000', 'epochs': '1', 'extra_center_factor': 'auto', 'local_lloyd_max_iter': '300', 'local_lloyd_tol': '0.0001', 'local_lloyd_init_method': 'kmeans++', 'local_lloyd_num_trials': 'auto', 'half_life_time_size': '0', 'eval_metrics': '[\"msd\"]', 'force_dense': 'true', '_disable_wait_to_read': 'false', '_enable_profiler': 'false', '_kvstore': 'auto', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': '1', '_num_slices': '1', '_tuning_objective_metric': ''}\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:39 INFO 140569316194112] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'feature_dim': '2', 'k': '10', 'force_dense': 'True'}\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:39 INFO 140569316194112] Final configuration: {'init_method': 'random', 'mini_batch_size': '5000', 'epochs': '1', 'extra_center_factor': 'auto', 'local_lloyd_max_iter': '300', 'local_lloyd_tol': '0.0001', 'local_lloyd_init_method': 'kmeans++', 'local_lloyd_num_trials': 'auto', 'half_life_time_size': '0', 'eval_metrics': '[\"msd\"]', 'force_dense': 'True', '_disable_wait_to_read': 'false', '_enable_profiler': 'false', '_kvstore': 'auto', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': '1', '_num_slices': '1', '_tuning_objective_metric': '', 'feature_dim': '2', 'k': '10'}\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:39 WARNING 140569316194112] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:39 INFO 140569316194112] Using default worker.\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:39 INFO 140569316194112] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:39 INFO 140569316194112] Create Store: local\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] nvidia-smi: took 0.031 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] Setting up with params: {'init_method': 'random', 'mini_batch_size': '5000', 'epochs': '1', 'extra_center_factor': 'auto', 'local_lloyd_max_iter': '300', 'local_lloyd_tol': '0.0001', 'local_lloyd_init_method': 'kmeans++', 'local_lloyd_num_trials': 'auto', 'half_life_time_size': '0', 'eval_metrics': '[\"msd\"]', 'force_dense': 'True', '_disable_wait_to_read': 'false', '_enable_profiler': 'false', '_kvstore': 'auto', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': '1', '_num_slices': '1', '_tuning_objective_metric': '', 'feature_dim': '2', 'k': '10'}\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1624706620.0730767, \"EndTime\": 1624706620.0731237, \"Dimensions\": {\"Algorithm\": \"AWS/KMeansWebscale\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5000.0, \"count\": 1, \"min\": 5000, \"max\": 5000}, \"Total Batches Seen\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Max Records Seen Between Resets\": {\"sum\": 5000.0, \"count\": 1, \"min\": 5000, \"max\": 5000}, \"Max Batches Seen Between Resets\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Reset Count\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Records Since Last Reset\": {\"sum\": 5000.0, \"count\": 1, \"min\": 5000, \"max\": 5000}, \"Number of Batches Since Last Reset\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[2021-06-26 11:23:40.073] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 42, \"num_examples\": 1, \"num_bytes\": 160000}\u001b[0m\n",
      "\u001b[34m[2021-06-26 11:23:40.172] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 96, \"num_examples\": 4, \"num_bytes\": 576000}\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] processed a total of 18000 examples\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1624706620.073543, \"EndTime\": 1624706620.1730058, \"Dimensions\": {\"Algorithm\": \"AWS/KMeansWebscale\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 23000.0, \"count\": 1, \"min\": 23000, \"max\": 23000}, \"Total Batches Seen\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Max Records Seen Between Resets\": {\"sum\": 18000.0, \"count\": 1, \"min\": 18000, \"max\": 18000}, \"Max Batches Seen Between Resets\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 18000.0, \"count\": 1, \"min\": 18000, \"max\": 18000}, \"Number of Batches Since Last Reset\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] #throughput_metric: host=algo-1, train throughput=180746.5489420586 records/second\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 WARNING 140569316194112] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] shrinking 100 centers into 10\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] local kmeans attempt #0. Current mean square distance 42.664654\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] local kmeans attempt #1. Current mean square distance 41.043278\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] local kmeans attempt #2. Current mean square distance 42.236774\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] local kmeans attempt #3. Current mean square distance 42.583469\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] local kmeans attempt #4. Current mean square distance 47.491760\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] local kmeans attempt #5. Current mean square distance 42.191971\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] local kmeans attempt #6. Current mean square distance 44.187748\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] local kmeans attempt #7. Current mean square distance 40.953476\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] local kmeans attempt #8. Current mean square distance 39.229080\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] local kmeans attempt #9. Current mean square distance 41.071774\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] finished shrinking process. Mean Square Distance = 39\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] #quality_metric: host=algo-1, train msd <loss>=39.22908020019531\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] compute all data-center distances: inner product took: 27.7085%, (0.029359 secs)\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] predict compute msd took: 17.6438%, (0.018695 secs)\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] gradient: cluster size  took: 8.8069%, (0.009331 secs)\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] gradient: cluster center took: 8.5065%, (0.009013 secs)\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] collect from kv store took: 8.1730%, (0.008660 secs)\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] splitting centers key-value pair took: 7.7815%, (0.008245 secs)\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] batch data loading with context took: 7.4003%, (0.007841 secs)\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] compute all data-center distances: point norm took: 5.1817%, (0.005490 secs)\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] gradient: one_hot took: 5.0262%, (0.005326 secs)\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] update state and report convergance took: 2.9862%, (0.003164 secs)\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] compute all data-center distances: center norm took: 0.5074%, (0.000538 secs)\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] update set-up time took: 0.2088%, (0.000221 secs)\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] predict minus dist took: 0.0691%, (0.000073 secs)\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] TOTAL took: 0.1059560775756836\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1624706620.0307665, \"EndTime\": 1624706620.5523474, \"Dimensions\": {\"Algorithm\": \"AWS/KMeansWebscale\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 33.66541862487793, \"count\": 1, \"min\": 33.66541862487793, \"max\": 33.66541862487793}, \"epochs\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"update.time\": {\"sum\": 99.26319122314453, \"count\": 1, \"min\": 99.26319122314453, \"max\": 99.26319122314453}, \"_shrink.time\": {\"sum\": 375.5195140838623, \"count\": 1, \"min\": 375.5195140838623, \"max\": 375.5195140838623}, \"finalize.time\": {\"sum\": 377.27880477905273, \"count\": 1, \"min\": 377.27880477905273, \"max\": 377.27880477905273}, \"model.serialize.time\": {\"sum\": 1.7046928405761719, \"count\": 1, \"min\": 1.7046928405761719, \"max\": 1.7046928405761719}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/26/2021 11:23:40 INFO 140569316194112] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1624706620.552435, \"EndTime\": 1624706620.552731, \"Dimensions\": {\"Algorithm\": \"AWS/KMeansWebscale\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 12.622594833374023, \"count\": 1, \"min\": 12.622594833374023, \"max\": 12.622594833374023}, \"totaltime\": {\"sum\": 598.5908508300781, \"count\": 1, \"min\": 598.5908508300781, \"max\": 598.5908508300781}}}\n",
      "\u001b[0m\n",
      "\n",
      "2021-06-26 11:23:55 Uploading - Uploading generated training model\n",
      "2021-06-26 11:23:55 Completed - Training job completed\n",
      "Training seconds: 43\n",
      "Billable seconds: 13\n",
      "Managed Spot Training savings: 69.8%\n",
      "CPU times: user 775 ms, sys: 14.7 ms, total: 790 ms\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kmeans.fit(kmeans.record_set(data_train), job_name=job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Viewing the results\n",
    "In this step we will take a look at the model artifact SageMaker created for us and stored onto S3. We have to do a few special things to see the latitude and longitude for our 10 clusters (and the center points of those clusters)\n",
    "\n",
    "[See the documentation of deserilization here](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html#td-deserialization)\n",
    "\n",
    "At this point we need to \"deserilize\" the model artifact. Here we are going to open and review them in our notebook instance. We can unzip the model artifact which will contain model_algo-1. This is just a serialized Apache MXNet object. From here we can load that serialized object into a numpy.ndarray and then extract the clustered centroids from the numpy.ndarray.\n",
    "\n",
    "After we extract the results into a DataFrame of latitudes and longitudes, we can create a CSV with that data, load it onto S3 and then visualize it with QuickSight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2304"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "model_key = 'model-artifacts/' + job_name + '/output/model.tar.gz'\n",
    "\n",
    "boto3.resource('s3').Bucket(bucket).download_file(model_key, 'model.tar.gz')\n",
    "os.system('tar -zxvf model.tar.gz')\n",
    "os.system('unzip model_algo-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mxnet\n",
      "  Downloading mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 46.9 MB 12.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet) (2.25.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet) (1.19.5)\n",
      "Collecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (1.26.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (2021.5.30)\n",
      "Installing collected packages: graphviz, mxnet\n",
      "Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n"
     ]
    }
   ],
   "source": [
    "!pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "Kmeans_model_params = mx.ndarray.load('model_algo-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-31.498852</td>\n",
       "      <td>146.292389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.107868</td>\n",
       "      <td>-87.831512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.544960</td>\n",
       "      <td>3.668381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.704254</td>\n",
       "      <td>-117.534378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.267736</td>\n",
       "      <td>87.902260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41.249573</td>\n",
       "      <td>-75.198082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>47.859707</td>\n",
       "      <td>-122.729187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30.933615</td>\n",
       "      <td>-82.302933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35.250290</td>\n",
       "      <td>-99.167221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24.602896</td>\n",
       "      <td>-151.607056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude   longitude\n",
       "0 -31.498852  146.292389\n",
       "1  41.107868  -87.831512\n",
       "2  50.544960    3.668381\n",
       "3  35.704254 -117.534378\n",
       "4  13.267736   87.902260\n",
       "5  41.249573  -75.198082\n",
       "6  47.859707 -122.729187\n",
       "7  30.933615  -82.302933\n",
       "8  35.250290  -99.167221\n",
       "9  24.602896 -151.607056"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_centroids_kmeans = pd.DataFrame(Kmeans_model_params[0].asnumpy())\n",
    "cluster_centroids_kmeans.columns=df_geo.columns\n",
    "cluster_centroids_kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and upload this dataset onto S3 and view within QuickSight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'CVSHXTY39KE9RQXC',\n",
       "  'HostId': 'VMcV01C7H/lrWlO8esR68BHonqEqNiIu8Hqv15fyOQC51Y7NaZBFjMVIaKisCT0KwooiRPoKBPo=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'VMcV01C7H/lrWlO8esR68BHonqEqNiIu8Hqv15fyOQC51Y7NaZBFjMVIaKisCT0KwooiRPoKBPo=',\n",
       "   'x-amz-request-id': 'CVSHXTY39KE9RQXC',\n",
       "   'date': 'Sat, 26 Jun 2021 11:29:58 GMT',\n",
       "   'etag': '\"72c15d58882014506f7379dc8d9bce87\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"72c15d58882014506f7379dc8d9bce87\"'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "cluster_centroids_kmeans.to_csv(csv_buffer, index=False)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object(bucket, 'results/ten_locations_kmeans.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
