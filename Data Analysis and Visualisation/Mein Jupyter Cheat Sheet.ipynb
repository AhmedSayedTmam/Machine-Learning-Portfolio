{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CITY_DATA = { 'chicago': 'chicago.csv',\n",
    "              'new york city': 'new_york_city.csv',\n",
    "              'washington': 'washington.csv' }          # Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " while True:\n",
    "        # get user input for city (chicago, new york city, washington). HINT: Use a while loop to handle invalid inputs\n",
    "        city = input(\"Please enter the desired city from chicago or new york city or washington \").lower()\n",
    "        if city in CITY_DATA:\n",
    "            break          # keep entering the city till be in the dict then break from while \n",
    "        else:\n",
    "            print(\"Invalid city name\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the Start Time column to datetime\n",
    "df['Start Time'] = pd.to_datetime(df['Start Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract month and day of week from Start Time to create new columns\n",
    "df['month'] = df['Start Time'].dt.month\n",
    "df['day_of_week'] = df['Start Time'].dt.day_name()\n",
    "df['time'] = df['Start Time'].dt.time\n",
    "df['dates'] = df['Start Time'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by month to create the new dataframe\n",
    "df = df[df['month'] == month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the time taken\n",
    "start_time = time.time()\n",
    "print(\"\\nThis took %s seconds.\" % (time.time() - start_time))\n",
    "print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the most common \n",
    "common = df['  '].mode()[0]\n",
    "# ex, display the most common start hour\n",
    "df['Start Time'] = pd.to_datetime(df['Start Time'])\n",
    "df['hour'] = df['Start Time'].dt.hour\n",
    "common_start_hour = df['hour'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    while True:\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "import requests       # For downloading URLs\n",
    "import os      # For Handling Working Directory\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data frame top_profit\n",
    "df_new=pd.DataFrame()\n",
    "df = pd.read_csv(' .csv')\n",
    "df = pd.read_csv(' .tsv', sep='\\t' )\n",
    "df.info()\n",
    "df.head()\n",
    "df.sample()\n",
    "df.shape     # df.shape[0]   # df.shape[1]\n",
    "df.dtypes\n",
    "df.describe()\n",
    "df['column'].nunique()    # unique num in column\n",
    "df['column '].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['column '].isnull()]\n",
    "df= df[df.column.isnull()]\n",
    "df.isnull().sum()\n",
    "df[df['column']==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop('column', axis=1)\n",
    "df['column'] = df['column'].fillna(0)\n",
    "df['column'] = df['column'].astype(int)\n",
    "df['column'] = df['column'].astype(str)\n",
    "df['column'] = df['column'].astype(float)\n",
    "df['column'] = df['column'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.duplicated())\n",
    "df['column'].duplicated().value_counts()\n",
    "df[df.column.duplicated()]\n",
    "df[df.duplicated(['column'])]\n",
    "df= df.drop_duplicates('column')\n",
    "df= df.sort_values('column').drop_duplicates(subset='x', keep='last') # Dropping duplicated based on x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['column1','column2], axis=1, inplace=True)\n",
    "df.dropna(how = 'any',inplace = True)\n",
    "df.dropna(inplace =True)\n",
    "df.drop_duplicates(keep= 'first',inplace = True)\n",
    "# Dropping the row with its index no#\n",
    "df.drop(#, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['column'] = df['column'].str.replace('_',' ') \n",
    "df['column'] = df['column'].replace(0, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['p1'] = df['p1'].str.title()   #Converts first character of each word to uppercase and remaining to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('column').describe()\n",
    "sum= df.groupby('column1')['column2'].sum()\n",
    "sum.plot(figsize = (10,5))\n",
    "plt.xlabel('column1')\n",
    "plt.ylabel('sum')\n",
    "plt.title('      ');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new= pd.merge(df1, df2, how = 'left', on = ['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df1.set_index('user_id').join(df2.set_index('user_id'), how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[' column '].value_counts()   #or df. column .value_counts()\n",
    "df.column.value_counts().sort_index()        # sort_index(ascending=False or True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(' column != 10'), df.query(' column == 10') \n",
    "# Searching for the no of the match between 'str1' and 'str2'\n",
    "num = df.query(\"column1 == 'str1' and column2 == 'str2'\").shape[0]\n",
    "# Dropping the missmatch\n",
    "df.drop(df.query(\"column1 == 'str1' and (\"column2 == 'str2' \").index, inplace=True)\n",
    "# Double Check all of the correct rows were removed - this should be 0\n",
    "df[((df['column'] == 'str1' ) == (df['column'] == 'str1' )) == False].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean= df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['column']df['column'].str.match('[a-z]+')] = 'None' #Replace column starting with lowercase characters like a, an with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using random, choice with n_new size \n",
    "rand_arr= np.random.choice([1, 0], size=n_new, p=[P_new, (1-P_new)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(' .csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['column'].value_counts().plot(kind='bar')\n",
    "plt.title('  ')\n",
    "plt.xlabel('   ')\n",
    "plt.ylabel('   ');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['column'].hist(figsize = (10,10), bins = 50)\n",
    "plt.xlabel(' ')\n",
    "plt.ylabel(' ')\n",
    "plt.title('  ');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['column'].plot(kind = 'box', figsize = (10,10));\n",
    "plt.ylabel(' ')\n",
    "plt.xlabel('   ')\n",
    "plt.title('   ');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the bar chart in order\n",
    "base_color = sb.color_palette()[0]\n",
    "sb.countplot(data = df, x = 'column', color = base_color, order =df['column'].value_count().index )\n",
    "plt.title('   ')\n",
    "plt.xlabel('    ')\n",
    "plt.xticks(rotation = 90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Histogram for BorrowerRate(continous variable)\n",
    "binsize = 0.005\n",
    "bins = np.arange(df.column.min(), df.column.max()+binsize, binsize)\n",
    "plt.figure(figsize=[8, 5])\n",
    "plt.hist(data = df, x = 'column', bins = bins)\n",
    "plt.title('   ')\n",
    "plt.xlabel('    ')\n",
    "plt.ylabel('     ')\n",
    "plt.xticks([0.0,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binsize = 400\n",
    "bins = np.arange(0, df.column.max()+binsize, binsize)\n",
    "sb.distplot(df['column'], bins = bins, kde = False,hist_kws = {'alpha' : 1})\n",
    "plt.title('   ')\n",
    "plt.xlabel('  ')\n",
    "plt.ylabel('  ');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Boxplot column1 against column2\n",
    "plt.figure(figsize=[8, 5])\n",
    "sb.boxplot(data = df, x = 'column2', y = 'column1', color = base_color, order = df['column2'].value_counts().index)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('   ')\n",
    "plt.xlabel('    ')\n",
    "plt.ylabel('   ');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting column1 against column2 \n",
    "plt.figure(figsize = [15,10])\n",
    "sb.countplot(data = df, x = 'column2', hue = 'column1 ', order = df['column2 '].value_counts().index)\n",
    "plt.legend(loc = 1, ncol = 8, title = 'column1 ')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.title('    ')\n",
    "plt.xlabel('    ');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sb.FacetGrid(data= df, aspect=0.65, height=5, margin_titles=True, col='common_column', col_wrap=4)\n",
    "g.map(sb.violinplot, 'column1', 'column2')\n",
    "plt.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('      ')\n",
    "g.add_legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading URL Data\n",
    "url = 'https://   .csv'\n",
    "mypath ='C:/Users/admin/Desktop/Data'\n",
    "file_name = mypath + '/' + ' .csv'    \n",
    "if not os.path.exists(mypath):\n",
    "    os.mkdir(mypath)\n",
    "r = requests.get(url)\n",
    "with open((file_name), mode ='wb') as file:    # writing in binary mode\n",
    "    file.write(r.content)\n",
    "\n",
    "#When writing in binary mode, Python makes no changes to data as it is written to the file.\n",
    "#In text mode (when the b is excluded as in just w or when you specify text mode with wt), #however, Python will encode the text based on the default text encoding. Additionally,\n",
    "#Python will convert line endings (\\n) to whatever the platform-specific line ending is, \n",
    "#which would corrupt a binary file like an exe or png file.\n",
    "\n",
    "#Text mode should therefore be used when writing text files (whether using plain text or a #text-based format like CSV), while binary mode must be used when writing non-text files like #images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Case downloading from Twitter API & tweet_json\n",
    "\n",
    "# After getting the following keys from tweeter development acount \n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_token =  ''\n",
    "access_secret = ''\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True, parser = tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the tweet IDs in the WeRateDogs Twitter archive to download and store in list\n",
    "tweet_list = []\n",
    "no_tweets_for_ids = []\n",
    "\n",
    "for tweet_id in twitter_archive_enhanced['tweet_id']:   \n",
    "    try:\n",
    "        tweet_list.append(api.get_status(tweet_id, tweet_mode='extended'))\n",
    "    except Exception as e:\n",
    "        no_tweets_for_ids.append(tweet_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the downloaded data into a list\n",
    "list_dicts = []\n",
    "for json_tweet in tweet_list:\n",
    "    list_dicts.append(json_tweet)\n",
    "\n",
    "# writing this list into a txt file in my path folder \n",
    "mypath ='C:/Users/admin/Desktop/Data'\n",
    "file_name = mypath + '/' + 'tweet_json.txt'    \n",
    "with open(file_name, mode ='w') as file:\n",
    "        file.write(json.dumps(list_dicts, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a DataFrame from the tweet_json.txt file\n",
    "my_list = []\n",
    "with open('tweet_json.txt', encoding='utf-8') as json_file:  \n",
    "    all_data = json.load(json_file)\n",
    "    for each_dictionary in all_data:\n",
    "        tweet_id = each_dictionary['id']\n",
    "        favorite_count = each_dictionary['favorite_count']\n",
    "        retweet_count = each_dictionary['retweet_count']\n",
    "        followers_count = each_dictionary['user']['followers_count']\n",
    "        friends_count = each_dictionary['user']['friends_count']\n",
    "        my_list.append({'tweet_id': str(tweet_id),'favorite_count': int(favorite_count),\n",
    "                             'retweet_count': int(retweet_count),'followers_count': int(followers_count),\n",
    "                            'friends_count': int(friends_count)})\n",
    "        tweet_json = pd.DataFrame(my_list, columns = ['tweet_id', 'favorite_count','retweet_count','followers_count','friends_count']) #['tweet_id', 'favorite_count','retweet_count', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Function to get the highest and lowest data set\n",
    "def highest_lowest(data_name):\n",
    "    highest = df[data_name].idxmax()\n",
    "    highest_df = pd.DataFrame(df.loc[highest])\n",
    "    \n",
    "    lowest = df[data_name].idxmin()\n",
    "    lowest_df = pd.DataFrame(df.loc[lowest])\n",
    "    \n",
    "    high_low = pd.concat([highest_df, lowest_df], axis = 1)\n",
    "\n",
    "    return high_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It’s generally an indication that you don’t care about the current value of the variable\n",
    "#it is just idiomatic. It is also useful while debugging\n",
    "for _ in range(10000):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
