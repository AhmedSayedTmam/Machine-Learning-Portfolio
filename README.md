# Machine Learning Portfolio

This Repository contains portfolio of Machine Learning projects for academic, self learning and work purposes, presented in the form of iPython Notebooks.

![logo](./img/AWS ML.png)


## Contents

- ### Data Analysis and Visualization:
	- [Wrangle and Analyze The WeRateDogs Twitter archive](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/Data%20Analysis%20and%20Visualisation/0.Wrangle%20and%20Analyze%20The%20WeRateDogs%20Twitter%20archive): The dataset that is wrangled is the tweet archive of Twitter user @dog_rates, also known as WeRateDogs, starting with Gathering data then Assessing data and Cleaning data.
	- [Investigate a Dataset (TMDb Movie)](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/Data%20Analysis%20and%20Visualisation/1.Investigate%20a%20Dataset%20(TMDb%20Movie)): Investigate and explore this data set by proposing the answers of some questions.
	- [Analyze A/B Test Results](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/Data%20Analysis%20and%20Visualisation/2.Analyze_ab_test_results/Analyze_ab_test_results): The goal is to work through this notebook to help the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision using an A/B test.
	- [Loan Data from Prosper Exploration](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/Data%20Analysis%20and%20Visualisation/3.Loan%20Data%20from%20Prosper%20Exploration/Loan%20Data%20from%20Prosper%20Exploration): Exploratory Data Analysis of  data set that contains 113,937 loans with 81 variables on each loan, including loan amount, borrower rate (or interest rate), current loan status, borrower income, and many others.
	- [Netflix Movies and TV Shows Analysis](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/Data%20Analysis%20and%20Visualisation/4.Netflix%20Movies%20and%20TV%20Shows%20Analysis): Data Analysis and visualization of  Netflix data set that  consists of listings of all the movies and tv shows available on Netflix, along with details such as - cast, directors, ratings, release year, duration, etc.
  
	_Tools: Pandas, Numpy, Seaborn and Matplotlib_
  
- ### Simple Machine Learning NoteBooks: 
	- [ML with Regression](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/Simple%20Machine%20Learning%20NoteBooks/2.Regression): Simple Linear Regression, Multiple Linear Regression, Polynomial Regression, SVR, Decision Tree Regression, Random Forest Regression.
	
	- [ML with Classification](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/Simple%20Machine%20Learning%20NoteBooks/3.Classification): Logistic Regression, K-NN, SVM, Kernel SVM, Naive Bayes, Decision Tree Classification, Random Forest Classification.
	- [ML with Clustering](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/Simple%20Machine%20Learning%20NoteBooks/4.Clustering): K-Means, Hierarchical Clustering.
	- [ML with Association Rule Learning](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/Simple%20Machine%20Learning%20NoteBooks/5.Association%20Rule%20Learning/Apriori_Python): Apriori, Eclat. 
	- [ML with Reinforcement Learning](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/Simple%20Machine%20Learning%20NoteBooks/6.Reinforcement%20Learning): Upper Confidence Bound, Thompson Sampling. 
	- [ML with Natural Language Processing](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/Simple%20Machine%20Learning%20NoteBooks/7.Natural%20Language%20Processing%20(NLP)): Bag-of-words model and algorithms for NLP. 
	- [ML with Dimensionality Reduction](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/Simple%20Machine%20Learning%20NoteBooks/8.Dimensionality%20Reduction): PCA, LDA, Kernel PCA. 
	- [ML with Model Selection & Boosting](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/Simple%20Machine%20Learning%20NoteBooks/9.Model%20Selection%20%26%20Boosting): k-fold Cross Validation, Parameter Tuning, Grid Search, XGBoos
	- [Deep Learning](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/Simple%20Machine%20Learning%20NoteBooks/10.Deep%20Learning): Artificial Neural Networks, Convolutional Neural Networks.

	_Tools: Pandas, Numpy, scikit-learn , Seaborn and Matplotlib_


- ### TensorFlow for Deep Learning: 
	- [1.Classifying Images of Clothing](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/blob/main/TensorFlow%20for%20Deep%20Learning/01_classifying_images_of_clothing.ipynb): We'll build and train a neural network to classify images of clothing, like sneakers and shirts. We use [tf.keras](https://www.tensorflow.org/guide/keras), a high-level API to build and train models in TensorFlow.
	- [2.Classifying Images of Clothing with CNN](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/blob/main/TensorFlow%20for%20Deep%20Learning/02_image_classification_with_cnns.ipynb): We'll build and train a neural network to classify images of clothing, like sneakers and shirts. WE use [tf.keras](https://www.tensorflow.org/guide/keras), a high-level API to build and train models in TensorFlow.
	- [3.Classifying Images of dogs_vs_cats without augmentation](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/blob/main/TensorFlow%20for%20Deep%20Learning/03_dogs_vs_cats_without_augmentation.ipynb): We'll build an image classifier using `tf.keras.Sequential` model and load data using `tf.keras.preprocessing.image.ImageDataGenerator`.
	- [4.Classifying Images of dogs_vs_cats with augmentation](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/blob/main/TensorFlow%20for%20Deep%20Learning/04_dogs_vs_cats_with_augmentation.ipynb): We'll build an image classifier using `tf.keras.Sequential` model and load data using `tf.keras.preprocessing.image.ImageDataGenerator`.
	- [5.Classifying Images of flowers with data augmentation](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/blob/main/TensorFlow%20for%20Deep%20Learning/05_flowers_with_data_augmentation.ipynb): We will build an image classifier using `tf.keras.Sequential` model and load data using `tf.keras.preprocessing.image.ImageDataGenerator`.
	- [6.TensorFlow Hub and Transfer Learning for Dogs vs. Cats Dataset](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/blob/main/TensorFlow%20for%20Deep%20Learning/06_tensorflow_hub_and_transfer_learning.ipynb): We will use a TensorFlow Hub model for prediction  Dogs vs. Cats dataset and do simple transfer learning with TensorFlow Hub.
	- [7.TensorFlow Hub and Transfer Learning for Flowers Dataset](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/blob/main/TensorFlow%20for%20Deep%20Learning/07_flowers_with_transfer_learning.ipynb): We will use a TensorFlow Hub model for prediction  and do simple transfer learning with TensorFlow Hub..
	- [8.Saving and Loading Models](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/blob/main/TensorFlow%20for%20Deep%20Learning/08_saving_and_loading_models.ipynb): We will learn how we can take a trained model, save it, and then load it back to keep training it or use it to perform inference..
	- [9.Time series  and Forecasting](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/TensorFlow%20for%20Deep%20Learning/9.Time%20Series%20%26%20Forecasting): We will use different techniques like Naive Forecasting, Moving Average, Time Windows, RNN, LSTM and CNN
	- [10.Natural language processing](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/TensorFlow%20for%20Deep%20Learning/10.Natural%20language%20processing): We will use NLP with TensorFlow to tokenize words and create embeddings for use in NN and build RNNs in TensorFlow   .
	- _Tools: TensorFlow, tf.keras, Pandas, Numpy, scikit-learn , Seaborn and Matplotlib_
	
- ### AWS SageMaker: 

  - [Xgboost_Customer_Churn](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/AWS%20SageMaker/xgboost_customer_churn): Using ML to automate the identification of unhappy customers, also known as customer churn prediction.

  - [Recommend Movies or Shows to Users](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/AWS%20SageMaker/Amazon_Reviews-Student): Leveraging machine learning to create a recommendation engine to be used on the user website. We can use the data set to train a machine learning model to recommend movies/shows to watch.
  - [Predicting Credit Card Fraud ](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/AWS%20SageMaker/Credit_Card_Fraud_Detection): Leveraging machine learning to identify fraudulent credit card transactions before they have a larger impact on a company. We can use a dataset of past credit card transactions to train a machine learning model to predict if transactions are fraudulent or not.
  - [Predicting Airplane Delays](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/AWS%20SageMaker/Flight_Delay): Leveraging machine learning to identify whether the flight will be delayed due to weather. We can use the a dataset of on-time performance of domestic flights operated by large air carriers to train a machine learning model to predict if the flight is going to be delayed for the busiest airports.
  - [UFO Sightings K-Means Clustering](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/AWS%20SageMaker/UFO%20Sightings%20K-Means%20Clustering): Analyze where Mr. K should build his extraterrestrial life facilities using the K-Means algorithm
  - [UFO Sightings Algorithms Lab](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/AWS%20SageMaker/UFO%20Sightings%20Algorithms%20Lab): Build out models to use for predicting the legitimacy of a UFO sighting using the XGBoost and Linear Learner algorithm.
  - [UFO Sightings Implementation and Operations](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/AWS%20SageMaker/UFO%20Sightings%20Implementation%20and%20Operations): Train and deploy our model into SageMaker online hosting with 1 variant.

  _Tools: SageMaker session, IAM role, S3 bucket, Pandas, Numpy, scikit-learn , Seaborn and Matplotlib_


- ### AWS SageMaker Deep Dive Notebooks: 
	- [1.Blazingtext_text_classification_dbpedia](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/AWS%20SageMaker%20Deep%20Dive%20Notebooks/1.blazingtext_text_classification_dbpedia): Train the text classification model on the DBPedia Ontology Dataset as done by Zhang et al. The DBpedia ontology dataset is constructed by picking 14 nonoverlapping classes from DBpedia 2014. It has 560,000 training samples and 70,000 testing samples. The fields we used for this dataset contain title and abstract of each Wikipedia article.
	
	- [2.Hpo_xgboost_direct_marketing_sagemaker_python_sdk](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/AWS%20SageMaker%20Deep%20Dive%20Notebooks/2.hpo_xgboost_direct_marketing_sagemaker_python_sdk): Train a model which can be used to predict if a customer will enroll for a term deposit at a bank, after one or more phone calls. Hyperparameter tuning will be used in order to try multiple hyperparameter settings and produce the best model.
	- [3.Hpo_image_classification_warmstart](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/AWS%20SageMaker%20Deep%20Dive%20Notebooks/3.hpo_image_classification_warmstart): Demonstrating how to iteratively tune an image classifer leveraging the warm start feature of Amazon SageMaker Automatic Model Tuning. The caltech-256 dataset will be used to train the image classifier.
	- [4.Tensorflow_script_mode_training_and_serving](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/AWS%20SageMaker%20Deep%20Dive%20Notebooks/4.tensorflow_script_mode_training_and_serving): Using a training script format for TensorFlow that lets you execute any TensorFlow training script in SageMaker with minimal modification
	- [5.Scikit_learn_estimator_example_with_batch_transform](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/AWS%20SageMaker%20Deep%20Dive%20Notebooks/5.scikit_learn_estimator_example_with_batch_transform): Using Scikit-learn with Sagemaker by utilizing the pre-built container which is a popular Python machine learning framework. It includes a number of different algorithms for classification, regression, clustering, dimensionality reduction, and data/feature pre-processing.
	- [6.Inference Pipeline with Scikit-learn and Linear Learner](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/AWS%20SageMaker%20Deep%20Dive%20Notebooks/6.Inference%20Pipeline%20with%20Scikit-learn%20and%20Linear%20Learner): Demonstrating how you can build your ML Pipeline leveraging the Sagemaker Scikit-learn container and SageMaker Linear Learner algorithm & after the model is trained, deploy the Pipeline (Data preprocessing and Lineara Learner) as an Inference Pipeline behind a single Endpoint for real time inference and for batch inferences using Amazon SageMaker Batch Transform.
	- [7.Multiprocess Ensembler](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/AWS%20SageMaker%20Deep%20Dive%20Notebooks/7.Multiprocess%20Ensembler): After we already have train, test, and validation data. Then we can train & tune a large number of models, and pull the results back in using an ensembling approach that takes the maximum prediction out of each classifier.Finally, we'll use SageMaker Search to find the best performing models from our bucket, and run parallel batch transform jobs to run inference on all of your newly trained models.
	- [8.Xgboost_multi_model_endpoint_home_value](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/AWS%20SageMaker%20Deep%20Dive%20Notebooks/8.xgboost_multi_model_endpoint_home_value): To demonstrate how multi-model endpoints are created and used, we use a set of XGBoost models that each predict housing prices for a single location. This domain is used as a simple example to easily experiment with multi-model endpoints.

	_Tools: SageMaker session, IAM role, S3 bucket, Pandas, Numpy, scikit-learn , Seaborn and Matplotlib_

- ### Probabilistic Forecasting with DeepAR and AWS SageMaker: 

  -  [DeepAR-Electricity](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/blob/main/Probabilistic%20Forecasting%20with%20DeepAR%20and%20AWS%20SageMaker/DeepAR-Electricity.ipynb): using DeepAR on SageMaker for predicting energy consumption of customers over time, based on a collected dataset. 

  _Tools: SageMaker session, IAM role, S3 bucket, Pandas, Numpy, scikit-learn , Seaborn and Matplotlib_
  
  ### Machine Learning with Spark: 
  
  -  [Churn_Prediction_with_PySpark](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/blob/main/Machine%20Learning%20with%20Spark/Churn_Prediction_with_PySpark/Churn_Prediction_with_PySpark.ipynb): In this project, we managed to build an end-to-end scalable machine learning pipeline using Python API for Spark, PySpark, to identify churned users.The pipeline runs from cleaning and labeling data, through feature engineering and removing highly correlated featues, to model tuning using grid search with cross validation, to predicting the probabilities associated with users prone to churn.
  
  _Tools: Pandas, Numpy, scikit-learn , Seaborn, Matplotlib, and pyspark_


- ### Amazon SageMaker Neo: 
	-  [Image-classification-fulltraining-highlevel-neo](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/Amazon%20SageMaker%20Neo): Using the Amazon SageMaker Image Classification algorithm to train on the caltech-256 dataset and then we will demonstrate Amazon SageMaker Neo's ability to optimize models.
	
  _Tools: SageMaker session, IAM role, S3 bucket, Pandas, Numpy, scikit-learn , Seaborn and Matplotlib_


- ### Use Cases: 
	-  [Use Case 1 : Default of credit card clients](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/Use%20Cases/Use%20Case%201%20%20Default%20of%20credit%20card%20clients): Build, train to predict the target label Y Did the person pay default payment next month (Yes=1 or No=0 ). 
	- [Use Case 2 : Amazon Product Reviews](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/Use%20Cases/Use%20Case%202%20Amazon%20Product%20Reviews): Classify reviews as positive or negative for dataset about amazon product reviews, so we will make NLP then build, train and evaluate ML model to predict customers reviews as positive or negative. 
	- [Use Case 3 : Object-Detection](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/Use%20Cases/Use%20Case%203%20Object-Detection): Using a dataset from the inaturalist.org This dataset contains 500 images of bees that have been uploaded by inaturalist users for the purposes of recording the observation and identification.
	- [Use Case 4 : Movies Recommendation System](https://github.com/AhmedSayedTmam/Machine-Learning-Portfolio/tree/main/Use%20Cases/Use%20Case%204%20Movies%20Recommendation%20System): Implementing a recommendation algorithms using cosine similarity to build a model to come up with our final recommendation system.
	
	_Tools: SageMaker session, IAM role, S3 bucket, Pandas, Numpy, scikit-learn , Seaborn and Matplotlib_



